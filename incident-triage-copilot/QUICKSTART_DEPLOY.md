# Quick Start Guide

## âœ… What's Been Done

Your Incident Triage Copilot is now **ready for cloud deployment**! Here's what was added:

1. âœ… **Groq client** - Cloud LLM integration
2. âœ… **Dual provider support** - Switch between Ollama (local) and Groq (cloud)
3. âœ… **Secrets management** - Secure API key handling
4. âœ… **Deployment docs** - Step-by-step Streamlit Cloud guide

## ğŸš€ Next Steps

### Option 1: Test Locally with Groq

```bash
# 1. Add your Groq API key
# Edit .streamlit/secrets.toml and paste your key:
GROQ_API_KEY = "gsk_your_actual_key_here"

# 2. Already done - config.yaml is set to "groq"
# 3. Already done - groq package installed

# 4. Run the app
streamlit run app.py

# You should see: "âœ… Using Groq: llama-3.1-8b-instant"
```

### Option 2: Deploy to Streamlit Cloud (Public Demo)

**See [DEPLOYMENT.md](DEPLOYMENT.md) for full instructions**

Quick version:
1. Push code to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Create new app from your repo
4. Add `GROQ_API_KEY` in Advanced Settings â†’ Secrets
5. Deploy!

## ğŸ“ Files Added/Modified

**New files:**
- `src/llm/groq_client.py` - Groq API client
- `.streamlit/secrets.toml` - Your API key (not committed)
- `.streamlit/secrets.toml.example` - Template for others
- `DEPLOYMENT.md` - Full deployment guide
- `QUICKSTART_DEPLOY.md` - This file

**Modified files:**
- `app.py` - Added provider switching logic
- `config.yaml` - Changed to `provider: "groq"`
- `requirements.txt` - Added `groq>=0.4.0`
- `README.md` - Mentioned cloud deployment

## ğŸ”„ Switching Between Providers

### Use Groq (Cloud, for demos)
```yaml
# config.yaml
llm:
  provider: "groq"
  model: "llama-3.1-8b-instant"
```

### Use Ollama (Local, for development)
```yaml
# config.yaml
llm:
  provider: "ollama"
  model: "llama3.1:8b"
```

## ğŸ¯ Key Features

**With Groq:**
- âœ… Fast inference (~2-3s per request)
- âœ… No local setup needed
- âœ… 14,400 free requests/day
- âœ… Works on any machine
- âš ï¸ Data sent to cloud

**With Ollama:**
- âœ… 100% local/private
- âœ… No API limits
- âœ… Works offline
- âš ï¸ Requires 5GB+ RAM
- âš ï¸ Slower inference (~10-15s)

## ğŸ› Troubleshooting

**"GROQ_API_KEY not found"**
- Check `.streamlit/secrets.toml` has your key
- Format: `GROQ_API_KEY = "gsk_..."`

**"Module 'groq' not found"**
```bash
uv pip install groq
```

**Want to switch back to Ollama?**
```bash
# 1. Edit config.yaml - change provider to "ollama"
# 2. Restart app
streamlit run app.py
```

## ğŸ“Š Performance Comparison

| Feature | Ollama (Local) | Groq (Cloud) |
|---------|---------------|--------------|
| Speed | 10-15s/incident | 3-5s/incident |
| Cost | Free | Free (14.4K/day) |
| Privacy | 100% local | Cloud API |
| Setup | Install Ollama | API key only |
| RAM needed | 5GB+ | <500MB |

## ğŸ‰ You're Ready!

Your app is now configured for cloud deployment. When you're ready:
1. Get your Groq API key from [console.groq.com](https://console.groq.com)
2. Add it to `.streamlit/secrets.toml`
3. Test locally
4. Push to GitHub
5. Deploy to Streamlit Cloud

Questions? Check [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions!
