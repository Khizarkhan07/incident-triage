# Incident Triage Copilot Configuration

llm:
  provider: "groq"  # Options: "ollama" (local) or "groq" (cloud)
  model: "llama-3.1-8b-instant"  # For Groq. For Ollama use: "llama3.1:8b"
  base_url: "http://localhost:11434"  # Only used for Ollama
  temperature: 0.1
  max_tokens: 2048
  
  # For Groq: Set GROQ_API_KEY environment variable

embeddings:
  model: "all-MiniLM-L6-v2"  # Fast, local sentence-transformer
  dimension: 384

vector_store:
  type: "sqlite"
  path: "data/vector_store.db"
  top_k: 5

storage:
  incidents_dir: "data/incidents"
  logs_dir: "data/logs"
  runbooks_dir: "data/runbooks"
  golden_cases_dir: "data/golden_cases"
  feedback_file: "data/feedback.jsonl"

triage:
  severity_levels:
    - "SEV1"  # Critical
    - "SEV2"  # High
    - "SEV3"  # Medium
    - "SEV4"  # Low
  
  categories:
    - "Database"
    - "API/Service"
    - "Infrastructure"
    - "Network"
    - "Security"
    - "Performance"
    - "Data Pipeline"
    - "Frontend"

evaluation:
  metrics:
    - "classification_accuracy"
    - "root_cause_precision"
    - "citation_quality"
    - "time_to_suggestion"
  
  thresholds:
    min_accuracy: 0.80
    min_precision: 0.70
    max_time_seconds: 10

ui:
  page_title: "Incident Triage Copilot"
  page_icon: "ðŸš¨"
  layout: "wide"
